{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48a475b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import cvxpylayers\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from src.neural_net import *\n",
    "# from src.models import *\n",
    "from trainer import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60219cf",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d6f496",
   "metadata": {},
   "source": [
    "##### Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d7392e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 83904\n"
     ]
    }
   ],
   "source": [
    "relative_path = os.getcwd()\n",
    "relative_path = os.path.abspath(\"..\")\n",
    "dataset_fn = relative_path + '/robot_nav/data' + '/single.p'\n",
    "prob_features = ['x0', 'xg']\n",
    "\n",
    "data_file = open(dataset_fn,'rb')\n",
    "all_data = pickle.load(data_file)[:100000]  # use only part of the dataset for quick testing\n",
    "data_file.close()\n",
    "num_train = len(all_data)\n",
    "print(f\"Number of training samples: {num_train}\")\n",
    "\n",
    "X0 = np.vstack([all_data[ii]['x0'].T for ii in range(num_train)])  \n",
    "XG = np.vstack([all_data[ii]['xg'].T for ii in range(num_train)])  \n",
    "OBS = np.vstack([all_data[ii]['xg'].T for ii in range(num_train)])  \n",
    "XX = np.array([all_data[ii]['XX'] for ii in range(num_train)])\n",
    "UU = np.array([all_data[ii]['UU'] for ii in range(num_train)])\n",
    "YY = np.concatenate([all_data[ii]['YY'].astype(int) for ii in range(num_train)], axis=1).transpose(1,0,2)\n",
    "train_data = [{'x0': X0, 'xg': XG}, {'XX': XX, 'UU' : UU}, YY]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78137550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83904, 3, 20)\n",
      "(20,)\n",
      "(20,)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "print(YY.shape)\n",
    "\n",
    "for y in YY[0]:\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e75f77c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "for u in UU[0]:\n",
    "    print(u.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734f857f",
   "metadata": {},
   "source": [
    "##### Obstacle Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b537205e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Obs_info = np.array([[1.0,  0.0, 0.4, 0.5, 0.0],\n",
    "                     [0.7, -1.1, 0.5, 0.4, 0.0],\n",
    "                     [0.4, -2.5, 0.4, 0.5, 0.0]])\n",
    "n_obs = 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93e41ad",
   "metadata": {},
   "source": [
    "##### Dataset Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04b5b414",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 6\n",
    "\n",
    "X_train = train_data[0]  # Problem parameters, will be inputs of the NNs\n",
    "Y_train = train_data[2]  # Discrete solutions, will be outputs of the NNs\n",
    "P_train = train_data[1]  # Continuous trajectories, will be used as parameters in training\n",
    "num_train = Y_train.shape[0]\n",
    "y_shape = Y_train.shape[1:]\n",
    "n_y = int(np.prod(y_shape))\n",
    "\n",
    "feature_blocks = []\n",
    "for feature in prob_features:\n",
    "    if feature == \"obstacles_map\":\n",
    "        continue\n",
    "    values = X_train.get(feature)\n",
    "    if values is None:\n",
    "        print('Feature {} is unknown or missing'.format(feature))\n",
    "        continue\n",
    "    values = np.asarray(values)\n",
    "    if values.shape[0] != num_train:\n",
    "        raise ValueError(\n",
    "            f\"Feature '{feature}' has {values.shape[0]} samples, expected {num_train}\"\n",
    "        )\n",
    "    feature_blocks.append(values.reshape(num_train, -1))\n",
    "if feature_blocks:\n",
    "    features = np.concatenate(feature_blocks, axis=1)\n",
    "else:\n",
    "    features = np.zeros((num_train, 0))\n",
    "if features.shape[1] != n_features:\n",
    "    n_features = features.shape[1]\n",
    "labels = Y_train.reshape(num_train, n_y)\n",
    "# print(labels.shape)\n",
    "# print(labels[:20])\n",
    "labels_int = labels.astype(np.int64, copy=False)\n",
    "bit_shifts = np.arange(4 - 1, -1, -1, dtype=np.int64)\n",
    "outputs_bits = (labels_int[..., None] >> bit_shifts) & 1\n",
    "# print(outputs_bits.shape)\n",
    "outputs = outputs_bits.reshape(num_train, -1)\n",
    "\n",
    "# P_blocks = []\n",
    "# for sample in data_list:\n",
    "#     XX = sample[\"XX\"]            # shape (4, H+1) -> [x, y, vx, vy]\n",
    "#     UU = sample[\"UU\"]            # shape (2, H)\n",
    "#     # match layer outputs: keep full trajectories and controls together\n",
    "#     block = np.concatenate(\n",
    "#         [XX.reshape(-1), UU.reshape(-1)],\n",
    "#         axis=0,\n",
    "#     )\n",
    "#     P_blocks.append(block)\n",
    "\n",
    "# P_arr = np.stack(P_blocks)       # shape (N, 4*(H+1) + 2*H)\n",
    "\n",
    "X_arr = features\n",
    "Y_arr = outputs\n",
    "P_arr = P_train['XX'][:, :, :]\n",
    "Pu_arr = P_train['UU'][:, :, :]\n",
    "# P_arr = np.concatenate([P_train['XX'][:, :, 1:], P_train['UU']], axis=1)\n",
    "\n",
    "X_tensor = torch.from_numpy(X_arr).float()\n",
    "Y_tensor = torch.from_numpy(Y_arr).float()\n",
    "P_tensor = torch.from_numpy(P_arr).float()\n",
    "Pu_tensor = torch.from_numpy(Pu_arr).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d68c66f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "dataset = torch.utils.data.TensorDataset(X_tensor, Y_tensor, P_tensor, Pu_tensor)\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "n_train = int(0.9 * len(dataset))\n",
    "n_test = len(dataset) - n_train\n",
    "train_set, test_set = random_split(dataset, [n_train, n_test])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf407cc",
   "metadata": {},
   "source": [
    "## QP Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b1e6ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"cvxpy.reductions.solvers.solving_chain_utils\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "294f8e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_lab/workspace/l2o/SS_Learning_MIQP_1/.venv/lib/python3.12/site-packages/cvxpy/atoms/affine/reshape.py:68: FutureWarning: \n",
      "    You didn't specify the order of the reshape expression. The default order\n",
      "    used in CVXPY is Fortran ('F') order. This default will change to match NumPy's\n",
      "    default order ('C') in a future version of CVXPY.\n",
      "    To suppress this warning, please specify the order explicitly.\n",
      "    \n",
      "  warnings.warn(reshape_order_warning, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CvxpyLayer()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cvxpy_mpc_layer import *\n",
    "\n",
    "T = 0.25\n",
    "H = 20\n",
    "M = 1  # update if you have more robots\n",
    "bounds = {\n",
    "    \"x_max\": 2.00,\n",
    "    \"x_min\": -0.5,\n",
    "    \"y_max\": 0.5,\n",
    "    \"y_min\": -3.0,\n",
    "    \"v_max\": 0.50,\n",
    "    \"v_min\": -0.50,\n",
    "    \"u_max\": 0.50,\n",
    "    \"u_min\": -0.50,\n",
    "}\n",
    "weights = (1.0, 1.0, 10.0)  # (Wu, Wp, Wpt)\n",
    "d_min = 0.25\n",
    "\n",
    "# Obstacles exactly as in the simulator\n",
    "from Robots import obstacle\n",
    "obstacles = [\n",
    "    obstacle(1.0, 0.0, 0.4, 0.5, 0.0),\n",
    "    obstacle(0.7, -1.1, 0.5, 0.4, 0.0),\n",
    "    obstacle(0.40, -2.50, 0.4, 0.5, 0.0),\n",
    "]\n",
    "\n",
    "M = 1\n",
    "p = np.zeros((2, M))  # stack of robot positions; replace with actual state\n",
    "d_prox = 2.0\n",
    "coupling_pairs = [\n",
    "    (m, n)\n",
    "    for m in range(M)\n",
    "    for n in range(m + 1, M)\n",
    "    if np.linalg.norm(p[:, m] - p[:, n]) <= d_prox\n",
    "]\n",
    "\n",
    "cplayer, meta = build_mpc_cvxpy_layer(\n",
    "        T=.25,\n",
    "        H=20,\n",
    "        M=1,\n",
    "        bounds=bounds,\n",
    "        weights=weights,\n",
    "        d_min=d_min,\n",
    "        obstacles=obstacles,\n",
    "        coupling_pairs=coupling_pairs\n",
    "    )\n",
    "\n",
    "cplayer.to(torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6ed4902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6]) torch.Size([128, 240]) torch.Size([128, 4, 21])\n",
      "tensor([[0.0046, 0.0044, 0.0060, 0.0054, 0.0031, 0.0028, 0.0051, 0.0033, 0.0033,\n",
      "         0.0030, 0.0032, 0.0020, 0.0015, 0.0017, 0.0007, 0.0007, 0.0008, 0.0008,\n",
      "         0.0005, 0.0002],\n",
      "        [0.0096, 0.0077, 0.0084, 0.0077, 0.0066, 0.0109, 0.0090, 0.0033, 0.0086,\n",
      "         0.0076, 0.0066, 0.0064, 0.0063, 0.0066, 0.0051, 0.0042, 0.0029, 0.0019,\n",
      "         0.0011, 0.0003]])\n",
      "tensor([[0.0000, 0.0001, 0.0004, 0.0008, 0.0013, 0.0019, 0.0025, 0.0030, 0.0032,\n",
      "         0.0034, 0.0034, 0.0032, 0.0029, 0.0025, 0.0022, 0.0020, 0.0018, 0.0016,\n",
      "         0.0013, 0.0011, 0.0009],\n",
      "        [0.0000, 0.0003, 0.0010, 0.0018, 0.0025, 0.0031, 0.0037, 0.0044, 0.0051,\n",
      "         0.0058, 0.0062, 0.0063, 0.0062, 0.0060, 0.0058, 0.0056, 0.0051, 0.0045,\n",
      "         0.0037, 0.0028, 0.0021],\n",
      "        [0.0000, 0.0011, 0.0015, 0.0016, 0.0021, 0.0027, 0.0026, 0.0016, 0.0017,\n",
      "         0.0014, 0.0010, 0.0011, 0.0015, 0.0013, 0.0011, 0.0010, 0.0010, 0.0010,\n",
      "         0.0011, 0.0012, 0.0013],\n",
      "        [0.0000, 0.0024, 0.0031, 0.0040, 0.0037, 0.0035, 0.0029, 0.0037, 0.0040,\n",
      "         0.0033, 0.0033, 0.0033, 0.0033, 0.0035, 0.0035, 0.0032, 0.0028, 0.0029,\n",
      "         0.0033, 0.0036, 0.0037]])\n",
      "torch.Size([128, 2, 21])\n",
      "torch.Size([128, 2, 21])\n",
      "torch.Size([128, 4, 21])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for x, y, p, pu in train_loader:\n",
    "    print(x.shape, y.shape, p.shape)\n",
    "    \n",
    "    u_opt, p_opt, v_opt, s_opt = cplayer(\n",
    "        x[:, 0:2], x[:, 2:4], x[:, 4:6], y.reshape(-1, 3, 1, 20, 4)\n",
    "    )\n",
    "    \n",
    "    # print(u_opt)\n",
    "    # print(pu)\n",
    "    \n",
    "    threshold = 1e-3\n",
    "    diff = torch.abs(u_opt - pu).clone()\n",
    "    diff[diff < threshold] = 0\n",
    "    print(diff.mean(dim=0))\n",
    "    \n",
    "    # print('--------------------------\\n\\n')\n",
    "    # # print(p_opt)\n",
    "    # # print(v_opt)\n",
    "    # # print(v_opt.shape)\n",
    "    # # print(p)\n",
    "    \n",
    "    # # print(torch.abs(torch.cat([p_opt, v_opt], dim=1) - p))\n",
    "    \n",
    "    threshold = 1e-3\n",
    "    diff = torch.abs(torch.cat([p_opt, v_opt], dim=1) - p).clone()\n",
    "    diff[diff < threshold] = 0\n",
    "    print(diff.mean(dim=0))\n",
    "    \n",
    "    print(p_opt.shape)\n",
    "    print(v_opt.shape)\n",
    "    print(p.shape)\n",
    "    \n",
    "    # obj.backward()\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48972000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 4, 20])\n",
      "tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.9605e-08, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        2.9802e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9802e-08, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        5.9605e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.9605e-08, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 5.9605e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        2.9802e-08, 0.0000e+00, 0.0000e+00, 5.9605e-08, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00])\n"
     ]
    }
   ],
   "source": [
    "from cons_utils import *\n",
    "\n",
    "# y_reshape = y.reshape(-1, 3, 20, 4)\n",
    "# y_reshape = y_reshape.swapaxes(2,3).float()\n",
    "\n",
    "# p_reshape = p.swapaxes(1,2).float()\n",
    "# print(p_reshape.shape)\n",
    "y_reshape = NNoutput_reshape_torch(y, 3)\n",
    "print(y_reshape.shape)\n",
    "print(constraint_violation_torch(y_reshape, p[:,:2,]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4af8607c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c9966d",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57a5bc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcdbb2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 6\n",
    "n_output = 240\n",
    "\n",
    "nn_model = MLPWithSTE(insize=n_input, outsize=n_output,\n",
    "                bias=True,\n",
    "                linear_map=torch.nn.Linear,\n",
    "                nonlin=nn.ReLU,\n",
    "                hsizes=[128] * 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad77eff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = SSL_MIQP_incorporated(nn_model, cplayer, 6, 4, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fcc5064",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "dt_string = now.strftime(\"%Y%m%d_%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e106208",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmux2001\u001b[0m (\u001b[33mmux2001-xxxxxlab-test1\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/x_lab/workspace/l2o/SS_Learning_MIQP_1/robot_nav/wandb/run-20251103_155304-q1en13we</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mux2001-xxxxxlab-test1/l2o_ssl_miqp_robot_nav/runs/q1en13we' target=\"_blank\">experiment_1_20251103_155303</a></strong> to <a href='https://wandb.ai/mux2001-xxxxxlab-test1/l2o_ssl_miqp_robot_nav' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mux2001-xxxxxlab-test1/l2o_ssl_miqp_robot_nav' target=\"_blank\">https://wandb.ai/mux2001-xxxxxlab-test1/l2o_ssl_miqp_robot_nav</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mux2001-xxxxxlab-test1/l2o_ssl_miqp_robot_nav/runs/q1en13we' target=\"_blank\">https://wandb.ai/mux2001-xxxxxlab-test1/l2o_ssl_miqp_robot_nav/runs/q1en13we</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1 | step 50] validation: loss = 7.3815, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 8.1074, supervised_loss = 0.1973, \n",
      "[epoch 1 | step 100] validation: loss = 4.8259, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 5.2941, supervised_loss = 0.1920, \n",
      "[epoch 1 | step 150] validation: loss = 5.3383, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 5.8582, supervised_loss = 0.1921, \n",
      "[epoch 1 | step 200] validation: loss = 4.2987, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 4.7138, supervised_loss = 0.1902, \n",
      "[epoch 1 | step 250] validation: loss = 4.1418, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 4.5412, supervised_loss = 0.1892, \n",
      "[epoch 1 | step 300] validation: loss = 3.6514, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 4.0014, supervised_loss = 0.1871, \n",
      "[epoch 1 | step 350] validation: loss = 1.6527, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 1.8015, supervised_loss = 0.1807, \n",
      "[epoch 1 | step 400] validation: loss = 1.5307, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 1.6674, supervised_loss = 0.1785, \n",
      "[epoch 1 | step 450] validation: loss = 2.7990, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 3.0634, supervised_loss = 0.1827, \n",
      "[epoch 1 | step 500] validation: loss = 0.8965, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 0.9693, supervised_loss = 0.1776, \n",
      "[epoch 1 | step 550] validation: loss = 1.0068, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 1.0912, supervised_loss = 0.1730, \n",
      "[epoch 2 | step 600] validation: loss = 1.3901, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 1.5126, supervised_loss = 0.1798, \n",
      "[epoch 2 | step 650] validation: loss = 0.7582, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 0.8177, supervised_loss = 0.1716, \n",
      "[epoch 2 | step 700] validation: loss = 0.4778, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 0.5085, supervised_loss = 0.1750, \n",
      "[epoch 2 | step 750] validation: loss = 0.5088, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 0.5425, supervised_loss = 0.1760, \n",
      "[epoch 2 | step 800] validation: loss = 0.4298, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 0.4561, supervised_loss = 0.1711, \n",
      "[epoch 2 | step 850] validation: loss = 0.9795, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 1.0615, supervised_loss = 0.1695, \n",
      "[epoch 2 | step 900] validation: loss = 0.9808, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 1.0628, supervised_loss = 0.1710, \n",
      "[epoch 2 | step 950] validation: loss = 0.2537, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 0.2626, supervised_loss = 0.1670, \n",
      "[epoch 2 | step 1000] validation: loss = 0.3102, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 0.3247, supervised_loss = 0.1684, \n",
      "[epoch 2 | step 1050] validation: loss = 0.3937, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 0.4160, supervised_loss = 0.1746, \n",
      "[epoch 2 | step 1100] validation: loss = 0.4104, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 0.4349, supervised_loss = 0.1698, \n",
      "Learning rate updated: 0.001000 -> 0.000500\n",
      "[epoch 2 | step 1150] validation: loss = 0.1475, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 0.1457, supervised_loss = 0.1673, \n",
      "[epoch 3 | step 1200] validation: loss = 0.1530, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 0.1524, supervised_loss = 0.1611, \n",
      "[epoch 3 | step 1250] validation: loss = 0.1797, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 0.1815, supervised_loss = 0.1642, \n",
      "[epoch 3 | step 1300] validation: loss = 0.2512, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 0.2599, supervised_loss = 0.1669, \n",
      "[epoch 3 | step 1350] validation: loss = 0.1347, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 0.1317, supervised_loss = 0.1653, \n",
      "[epoch 3 | step 1400] validation: loss = 0.1739, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 0.1749, supervised_loss = 0.1652, \n",
      "[epoch 3 | step 1450] validation: loss = 0.1378, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 0.1351, supervised_loss = 0.1661, \n",
      "[epoch 3 | step 1500] validation: loss = 0.0862, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 0.0785, supervised_loss = 0.1634, \n",
      "[epoch 3 | step 1550] validation: loss = 0.1900, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 0.1915, supervised_loss = 0.1765, \n",
      "[epoch 3 | step 1600] validation: loss = 0.2121, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 0.2161, supervised_loss = 0.1745, \n",
      "[epoch 3 | step 1650] validation: loss = 0.1339, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 0.1305, supervised_loss = 0.1686, \n",
      "Learning rate updated: 0.000500 -> 0.000250\n",
      "[epoch 3 | step 1700] validation: loss = 0.1122, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 0.1068, supervised_loss = 0.1679, \n",
      "[epoch 3 | step 1750] validation: loss = 0.0589, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 0.0481, supervised_loss = 0.1675, \n",
      "[epoch 4 | step 1800] validation: loss = 0.0663, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 0.0563, supervised_loss = 0.1671, \n",
      "[epoch 4 | step 1850] validation: loss = 0.0593, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 0.0490, supervised_loss = 0.1628, \n",
      "[epoch 4 | step 1900] validation: loss = 0.0533, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 0.0423, supervised_loss = 0.1637, \n",
      "[epoch 4 | step 1950] validation: loss = 0.0470, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 0.0358, supervised_loss = 0.1595, \n",
      "[epoch 4 | step 2000] validation: loss = 0.1365, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 0.1335, supervised_loss = 0.1678, \n",
      "[epoch 4 | step 2050] validation: loss = 0.1250, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 0.1213, supervised_loss = 0.1629, \n",
      "Learning rate updated: 0.000250 -> 0.000125\n",
      "[epoch 4 | step 2100] validation: loss = 0.0572, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 0.0471, supervised_loss = 0.1590, \n",
      "[epoch 4 | step 2150] validation: loss = 0.0383, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 0.0265, supervised_loss = 0.1563, \n",
      "[epoch 4 | step 2200] validation: loss = 0.0371, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 0.0252, supervised_loss = 0.1569, \n",
      "[epoch 4 | step 2250] validation: loss = 0.0434, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 0.0325, supervised_loss = 0.1528, \n",
      "[epoch 4 | step 2300] validation: loss = 0.0747, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 0.0669, supervised_loss = 0.1531, \n",
      "Learning rate updated: 0.000125 -> 0.000063\n",
      "[epoch 4 | step 2350] validation: loss = 0.0584, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 0.0490, supervised_loss = 0.1530, \n",
      "[epoch 5 | step 2400] validation: loss = 0.0524, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 0.0426, supervised_loss = 0.1517, \n",
      "[epoch 5 | step 2450] validation: loss = 0.0454, obj_val = 0.0000, opt_gap = nan %, slack_pen = 0.0000, y_penalty = 0.0349, supervised_loss = 0.1506, \n",
      "Early stopping triggered!\n"
     ]
    }
   ],
   "source": [
    "True\n",
    "training_params = {}\n",
    "training_params['TRAINING_EPOCHS'] = int(5)\n",
    "training_params['CHECKPOINT_AFTER'] = int(50)\n",
    "training_params['LEARNING_RATE'] = 1e-3\n",
    "training_params['WEIGHT_DECAY'] = 1e-5\n",
    "training_params['PATIENCE'] = 5\n",
    "training_params['WANDB_PROJECT'] = \"l2o_ssl_miqp_robot_nav\"\n",
    "training_params['RUN_NAME'] = \"experiment_1_\" + dt_string\n",
    "\n",
    "slack_weight = 1e3\n",
    "constraint_weight = 1e6\n",
    "supervised_weight = 1e5\n",
    "loss_weights = [0.0, slack_weight, constraint_weight, supervised_weight]\n",
    "\n",
    "# Model.train_SL(\n",
    "#     train_loader=train_loader, \n",
    "#     test_loader=test_loader, \n",
    "#     training_params=training_params, \n",
    "#     # loss_weights=loss_weights,\n",
    "#     wandb_log = True)\n",
    "# Model.train_SSL(\n",
    "#     train_loader=train_loader, \n",
    "#     test_loader=test_loader, \n",
    "#     training_params=training_params, \n",
    "#     loss_weights=loss_weights,\n",
    "#     wandb_log = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451ef3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_model(nn_model, test_loader, device):\n",
    "#     nn_model.eval()\n",
    "#     supervised_loss_fn = torch.nn.HuberLoss()\n",
    "#     val_loss_total = 0.0\n",
    "#     with torch.no_grad():\n",
    "#         for val_theta_batch, val_y_gt_batch, _, _ in test_loader:\n",
    "#             val_theta_batch = val_theta_batch.to(device)\n",
    "#             val_y_gt_batch = val_y_gt_batch.to(device)\n",
    "#             # ---- Predict y from theta ----\n",
    "#             y_pred_test = nn_model(val_theta_batch).float() # (B, ny), hard {0,1}\n",
    "#             val_loss_total += supervised_loss_fn(y_pred_test, val_y_gt_batch.float()).item()                           \n",
    "#     avg_val_loss = val_loss_total / len(test_loader)\n",
    "\n",
    "#     print(f\"validation loss = {avg_val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f8aa52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss = 0.1506\n"
     ]
    }
   ],
   "source": [
    "# evaluate_model(Model.nn_model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10eada55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1 | step 1] training loss = 0.2570, validation loss = 0.2545\n",
      "[epoch 1 | step 50] training loss = 0.0690, validation loss = 0.0690\n",
      "[epoch 1 | step 100] training loss = 0.0392, validation loss = 0.0393\n",
      "[epoch 1 | step 150] training loss = 0.0416, validation loss = 0.0376\n",
      "[epoch 1 | step 200] training loss = 0.0382, validation loss = 0.0475\n",
      "[epoch 1 | step 250] training loss = 0.0351, validation loss = 0.0354\n",
      "[epoch 1 | step 300] training loss = 0.0349, validation loss = 0.0405\n",
      "[epoch 1 | step 350] training loss = 0.0552, validation loss = 0.0429\n",
      "[epoch 1 | step 400] training loss = 0.0475, validation loss = 0.0469\n",
      "[epoch 1 | step 450] training loss = 0.0380, validation loss = 0.0363\n",
      "Learning rate updated: 0.001000 -> 0.000500\n",
      "[epoch 1 | step 500] training loss = 0.0282, validation loss = 0.0295\n",
      "[epoch 1 | step 550] training loss = 0.0344, validation loss = 0.0328\n"
     ]
    }
   ],
   "source": [
    "nn_model_1 = MLPWithSTE(insize=n_input, outsize=n_output,\n",
    "                bias=True,\n",
    "                linear_map=torch.nn.Linear,\n",
    "                nonlin=nn.ReLU,\n",
    "                hsizes=[128] * 4)\n",
    "\n",
    "ModelSL = SSL_MIQP_incorporated(nn_model_1, cplayer, 6, 4, device=device)\n",
    "\n",
    "training_params = {}\n",
    "training_params['TRAINING_EPOCHS'] = int(1)\n",
    "training_params['CHECKPOINT_AFTER'] = int(50)\n",
    "training_params['LEARNING_RATE'] = 1e-3\n",
    "training_params['WEIGHT_DECAY'] = 1e-5\n",
    "training_params['PATIENCE'] = 5\n",
    "training_params['WANDB_PROJECT'] = \"l2o_ssl_miqp_robot_nav\"\n",
    "training_params['RUN_NAME'] = \"experiment_1_\" + dt_string\n",
    "\n",
    "slack_weight = 1e3\n",
    "constraint_weight = 1e6\n",
    "supervised_weight = 1e5\n",
    "loss_weights = [0.0, slack_weight, constraint_weight, supervised_weight]\n",
    "\n",
    "ModelSL.train_SL(\n",
    "    train_loader=train_loader, \n",
    "    test_loader=test_loader, \n",
    "    training_params=training_params, \n",
    "    # loss_weights=loss_weights,\n",
    "    wandb_log = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ea50f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: Avg Supervised Loss = 0.0398, Avg Constraint Violation = 1.9343, Avg Optimality Gap = 242.7286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'avg_supervised_loss': 0.039840271809335914,\n",
       " 'avg_constraint_violation': 1.9343116825277156,\n",
       " 'avg_optimality_gap': 242.7285674124053}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate_model(ModelSL.nn_model, test_loader, device)\n",
    "ModelSL.evaluate(test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SS_Learning_MIQP_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
