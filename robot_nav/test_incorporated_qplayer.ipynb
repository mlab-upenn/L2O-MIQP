{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48a475b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import cvxpylayers\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from src.neural_net import *\n",
    "from src.models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60219cf",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d6f496",
   "metadata": {},
   "source": [
    "##### Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d7392e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 83904\n"
     ]
    }
   ],
   "source": [
    "relative_path = os.getcwd()\n",
    "relative_path = os.path.abspath(\"..\")\n",
    "dataset_fn = relative_path + '/robot_nav/data' + '/single.p'\n",
    "prob_features = ['x0', 'xg']\n",
    "\n",
    "data_file = open(dataset_fn,'rb')\n",
    "all_data = pickle.load(data_file)[:100000]  # use only part of the dataset for quick testing\n",
    "data_file.close()\n",
    "num_train = len(all_data)\n",
    "print(f\"Number of training samples: {num_train}\")\n",
    "\n",
    "X0 = np.vstack([all_data[ii]['x0'].T for ii in range(num_train)])  \n",
    "XG = np.vstack([all_data[ii]['xg'].T for ii in range(num_train)])  \n",
    "OBS = np.vstack([all_data[ii]['xg'].T for ii in range(num_train)])  \n",
    "XX = np.array([all_data[ii]['XX'] for ii in range(num_train)])\n",
    "UU = np.array([all_data[ii]['UU'] for ii in range(num_train)])\n",
    "YY = np.concatenate([all_data[ii]['YY'].astype(int) for ii in range(num_train)], axis=1).transpose(1,0,2)\n",
    "train_data = [{'x0': X0, 'xg': XG}, {'XX': XX, 'UU' : UU}, YY]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78137550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83904, 3, 20)\n",
      "(20,)\n",
      "(20,)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "print(YY.shape)\n",
    "\n",
    "for y in YY[0]:\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e75f77c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "for u in UU[0]:\n",
    "    print(u.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734f857f",
   "metadata": {},
   "source": [
    "##### Obstacle Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b537205e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Obs_info = np.array([[1.0,  0.0, 0.4, 0.5, 0.0],\n",
    "                     [0.7, -1.1, 0.5, 0.4, 0.0],\n",
    "                     [0.4, -2.5, 0.4, 0.5, 0.0]])\n",
    "n_obs = 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93e41ad",
   "metadata": {},
   "source": [
    "##### Dataset Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04b5b414",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 6\n",
    "\n",
    "X_train = train_data[0]  # Problem parameters, will be inputs of the NNs\n",
    "Y_train = train_data[2]  # Discrete solutions, will be outputs of the NNs\n",
    "P_train = train_data[1]  # Continuous trajectories, will be used as parameters in training\n",
    "num_train = Y_train.shape[0]\n",
    "y_shape = Y_train.shape[1:]\n",
    "n_y = int(np.prod(y_shape))\n",
    "\n",
    "feature_blocks = []\n",
    "for feature in prob_features:\n",
    "    if feature == \"obstacles_map\":\n",
    "        continue\n",
    "    values = X_train.get(feature)\n",
    "    if values is None:\n",
    "        print('Feature {} is unknown or missing'.format(feature))\n",
    "        continue\n",
    "    values = np.asarray(values)\n",
    "    if values.shape[0] != num_train:\n",
    "        raise ValueError(\n",
    "            f\"Feature '{feature}' has {values.shape[0]} samples, expected {num_train}\"\n",
    "        )\n",
    "    feature_blocks.append(values.reshape(num_train, -1))\n",
    "if feature_blocks:\n",
    "    features = np.concatenate(feature_blocks, axis=1)\n",
    "else:\n",
    "    features = np.zeros((num_train, 0))\n",
    "if features.shape[1] != n_features:\n",
    "    n_features = features.shape[1]\n",
    "labels = Y_train.reshape(num_train, n_y)\n",
    "# print(labels.shape)\n",
    "# print(labels[:20])\n",
    "labels_int = labels.astype(np.int64, copy=False)\n",
    "bit_shifts = np.arange(4 - 1, -1, -1, dtype=np.int64)\n",
    "outputs_bits = (labels_int[..., None] >> bit_shifts) & 1\n",
    "# print(outputs_bits.shape)\n",
    "outputs = outputs_bits.reshape(num_train, -1)\n",
    "\n",
    "# P_blocks = []\n",
    "# for sample in data_list:\n",
    "#     XX = sample[\"XX\"]            # shape (4, H+1) -> [x, y, vx, vy]\n",
    "#     UU = sample[\"UU\"]            # shape (2, H)\n",
    "#     # match layer outputs: keep full trajectories and controls together\n",
    "#     block = np.concatenate(\n",
    "#         [XX.reshape(-1), UU.reshape(-1)],\n",
    "#         axis=0,\n",
    "#     )\n",
    "#     P_blocks.append(block)\n",
    "\n",
    "# P_arr = np.stack(P_blocks)       # shape (N, 4*(H+1) + 2*H)\n",
    "\n",
    "X_arr = features\n",
    "Y_arr = outputs\n",
    "P_arr = P_train['XX'][:, :, :]\n",
    "Pu_arr = P_train['UU'][:, :, :]\n",
    "# P_arr = np.concatenate([P_train['XX'][:, :, 1:], P_train['UU']], axis=1)\n",
    "\n",
    "X_tensor = torch.from_numpy(X_arr).float()\n",
    "Y_tensor = torch.from_numpy(Y_arr).float()\n",
    "P_tensor = torch.from_numpy(P_arr).float()\n",
    "Pu_tensor = torch.from_numpy(Pu_arr).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68c66f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "dataset = torch.utils.data.TensorDataset(X_tensor, Y_tensor, P_tensor, Pu_tensor)\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "n_train = int(0.8 * len(dataset))\n",
    "n_test = len(dataset) - n_train\n",
    "train_set, test_set = random_split(dataset, [n_train, n_test])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf407cc",
   "metadata": {},
   "source": [
    "## QP Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b1e6ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"cvxpy.reductions.solvers.solving_chain_utils\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "294f8e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_lab/workspace/l2o/SS_Learning_MIQP_1/.venv/lib/python3.12/site-packages/cvxpy/atoms/affine/reshape.py:68: FutureWarning: \n",
      "    You didn't specify the order of the reshape expression. The default order\n",
      "    used in CVXPY is Fortran ('F') order. This default will change to match NumPy's\n",
      "    default order ('C') in a future version of CVXPY.\n",
      "    To suppress this warning, please specify the order explicitly.\n",
      "    \n",
      "  warnings.warn(reshape_order_warning, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from cvxpy_mpc_layer import *\n",
    "\n",
    "T = 0.25\n",
    "H = 20\n",
    "M = 1  # update if you have more robots\n",
    "bounds = {\n",
    "    \"x_max\": 2.00,\n",
    "    \"x_min\": -0.5,\n",
    "    \"y_max\": 0.5,\n",
    "    \"y_min\": -3.0,\n",
    "    \"v_max\": 0.50,\n",
    "    \"v_min\": -0.50,\n",
    "    \"u_max\": 0.50,\n",
    "    \"u_min\": -0.50,\n",
    "}\n",
    "weights = (1.0, 1.0, 10.0)  # (Wu, Wp, Wpt)\n",
    "d_min = 0.25\n",
    "\n",
    "# Obstacles exactly as in the simulator\n",
    "from Robots import obstacle\n",
    "obstacles = [\n",
    "    obstacle(1.0, 0.0, 0.4, 0.5, 0.0),\n",
    "    obstacle(0.7, -1.1, 0.5, 0.4, 0.0),\n",
    "    obstacle(0.40, -2.50, 0.4, 0.5, 0.0),\n",
    "]\n",
    "\n",
    "M = 1\n",
    "p = np.zeros((2, M))  # stack of robot positions; replace with actual state\n",
    "d_prox = 2.0\n",
    "coupling_pairs = [\n",
    "    (m, n)\n",
    "    for m in range(M)\n",
    "    for n in range(m + 1, M)\n",
    "    if np.linalg.norm(p[:, m] - p[:, n]) <= d_prox\n",
    "]\n",
    "\n",
    "cplayer, meta = build_mpc_cvxpy_layer(\n",
    "        T=.25,\n",
    "        H=20,\n",
    "        M=1,\n",
    "        bounds=bounds,\n",
    "        weights=weights,\n",
    "        d_min=d_min,\n",
    "        obstacles=obstacles,\n",
    "        coupling_pairs=coupling_pairs\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6ed4902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6]) torch.Size([128, 240]) torch.Size([128, 4, 21])\n",
      "Please consider re-formulating your problem so that it is always solvable or increasing the number of solver iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_lab/workspace/l2o/SS_Learning_MIQP_1/.venv/lib/python3.12/site-packages/diffcp/cone_program.py:212: SyntaxWarning: invalid escape sequence '\\i'\n",
      "  s \\in K                            y \\in K^*\n"
     ]
    },
    {
     "ename": "SolverError",
     "evalue": "Solver scs returned status unbounded",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mSolverError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x, y, p, pu \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[32m      2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(x.shape, y.shape, p.shape)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     u_opt, p_opt, v_opt, s_opt = \u001b[43mcplayer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m:\u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# print(u_opt)\u001b[39;00m\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# print(pu)\u001b[39;00m\n\u001b[32m     11\u001b[39m     threshold = \u001b[32m1e-3\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/l2o/SS_Learning_MIQP_1/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/l2o/SS_Learning_MIQP_1/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/l2o/SS_Learning_MIQP_1/.venv/lib/python3.12/site-packages/cvxpylayers/torch/cvxpylayer.py:164\u001b[39m, in \u001b[36mCvxpyLayer.forward\u001b[39m\u001b[34m(self, solver_args, *params)\u001b[39m\n\u001b[32m    149\u001b[39m info = {}\n\u001b[32m    150\u001b[39m f = _CvxpyLayerFn(\n\u001b[32m    151\u001b[39m     _forward_numpy=\u001b[38;5;28mself\u001b[39m._forward_numpy,\n\u001b[32m    152\u001b[39m     _backward_numpy=\u001b[38;5;28mself\u001b[39m._backward_numpy,\n\u001b[32m   (...)\u001b[39m\u001b[32m    162\u001b[39m     info=info,\n\u001b[32m    163\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m sol = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;28mself\u001b[39m.info = info\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m sol\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/l2o/SS_Learning_MIQP_1/.venv/lib/python3.12/site-packages/torch/autograd/function.py:581\u001b[39m, in \u001b[36mFunction.apply\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m    578\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch._C._are_functorch_transforms_active():\n\u001b[32m    579\u001b[39m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[32m    580\u001b[39m     args = _functorch.utils.unwrap_dead_wrappers(args)\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m    583\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[32m    584\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    585\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    586\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    587\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstaticmethod. For more details, please see \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    588\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    589\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/l2o/SS_Learning_MIQP_1/.venv/lib/python3.12/site-packages/cvxpylayers/torch/cvxpylayer.py:288\u001b[39m, in \u001b[36m_CvxpyLayerFn.<locals>._CvxpyLayerFnFn.forward\u001b[39m\u001b[34m(ctx, *params)\u001b[39m\n\u001b[32m    270\u001b[39m params_numpy = [to_numpy(p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params]\n\u001b[32m    272\u001b[39m context = ForwardContext(\n\u001b[32m    273\u001b[39m     gp=gp,\n\u001b[32m    274\u001b[39m     solve_and_derivative=\u001b[38;5;28many\u001b[39m(p.requires_grad \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params),\n\u001b[32m   (...)\u001b[39m\u001b[32m    285\u001b[39m     var_dict=var_dict,\n\u001b[32m    286\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m sol, info_forward = \u001b[43m_forward_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_numpy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[38;5;66;03m# convert to torch tensors and incorporate info_forward\u001b[39;00m\n\u001b[32m    291\u001b[39m sol = [to_torch(s, ctx.dtype, ctx.device) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m sol]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/l2o/SS_Learning_MIQP_1/.venv/lib/python3.12/site-packages/cvxpylayers/utils.py:93\u001b[39m, in \u001b[36mforward_numpy\u001b[39m\u001b[34m(params_numpy, context)\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m diffcp.SolverError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     89\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m     90\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease consider re-formulating your problem so that \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     91\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mit is always solvable or increasing the number of \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     92\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msolver iterations.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m     94\u001b[39m info[\u001b[33m'\u001b[39m\u001b[33msolve_time\u001b[39m\u001b[33m'\u001b[39m] = time.time() - start\n\u001b[32m     96\u001b[39m \u001b[38;5;66;03m# extract solutions and append along batch dimension\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/l2o/SS_Learning_MIQP_1/.venv/lib/python3.12/site-packages/cvxpylayers/utils.py:86\u001b[39m, in \u001b[36mforward_numpy\u001b[39m\u001b[34m(params_numpy, context)\u001b[39m\n\u001b[32m     84\u001b[39m         info[\u001b[33m'\u001b[39m\u001b[33mDT_batch\u001b[39m\u001b[33m'\u001b[39m] = DT_batch\n\u001b[32m     85\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m         xs, _, _ = \u001b[43mdiffcp\u001b[49m\u001b[43m.\u001b[49m\u001b[43msolve_only_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m            \u001b[49m\u001b[43mAs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcone_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43msolver_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m diffcp.SolverError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     89\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m     90\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease consider re-formulating your problem so that \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     91\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mit is always solvable or increasing the number of \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     92\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msolver iterations.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/l2o/SS_Learning_MIQP_1/.venv/lib/python3.12/site-packages/diffcp/cone_program.py:192\u001b[39m, in \u001b[36msolve_only_batch\u001b[39m\u001b[34m(As, bs, cs, cone_dicts, n_jobs_forward, warm_starts, **kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m args = [(A, b, c, cone_dict, warm_start, kwargs) \u001b[38;5;28;01mfor\u001b[39;00m A, b, c, cone_dict, warm_start \u001b[38;5;129;01min\u001b[39;00m\n\u001b[32m    190\u001b[39m         \u001b[38;5;28mzip\u001b[39m(As, bs, cs, cone_dicts, warm_starts)]\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m threadpool_limits(limits=\u001b[32m1\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     results = \u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstarmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43msolve_only_wrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m pool.close()\n\u001b[32m    194\u001b[39m xs = [r[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.11-linux-x86_64-gnu/lib/python3.12/multiprocessing/pool.py:375\u001b[39m, in \u001b[36mPool.starmap\u001b[39m\u001b[34m(self, func, iterable, chunksize)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstarmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    370\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''\u001b[39;00m\n\u001b[32m    371\u001b[39m \u001b[33;03m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[32m    372\u001b[39m \u001b[33;03m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[32m    373\u001b[39m \u001b[33;03m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[33;03m    '''\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.11-linux-x86_64-gnu/lib/python3.12/multiprocessing/pool.py:774\u001b[39m, in \u001b[36mApplyResult.get\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    772\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._value\n\u001b[32m    773\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.11-linux-x86_64-gnu/lib/python3.12/multiprocessing/pool.py:125\u001b[39m, in \u001b[36mworker\u001b[39m\u001b[34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[39m\n\u001b[32m    123\u001b[39m job, i, func, args, kwds = task\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     result = (\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    127\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m wrap_exception \u001b[38;5;129;01mand\u001b[39;00m func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _helper_reraises_exception:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.11-linux-x86_64-gnu/lib/python3.12/multiprocessing/pool.py:51\u001b[39m, in \u001b[36mstarmapstar\u001b[39m\u001b[34m(args)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstarmapstar\u001b[39m(args):\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstarmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/l2o/SS_Learning_MIQP_1/.venv/lib/python3.12/site-packages/diffcp/cone_program.py:147\u001b[39m, in \u001b[36msolve_only_wrapper\u001b[39m\u001b[34m(A, b, c, cone_dict, warm_start, kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msolve_only_wrapper\u001b[39m(A, b, c, cone_dict, warm_start, kwargs):\n\u001b[32m    146\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"A wrapper around solve_only for the batch function\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msolve_only\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m        \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcone_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwarm_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/l2o/SS_Learning_MIQP_1/.venv/lib/python3.12/site-packages/diffcp/cone_program.py:295\u001b[39m, in \u001b[36msolve_only\u001b[39m\u001b[34m(A, b, c, cone_dict, warm_start, solve_method, **kwargs)\u001b[39m\n\u001b[32m    292\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mFound a NaN in A.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m A.eliminate_zeros()\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m result = \u001b[43msolve_internal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcone_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwarm_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43msolve_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43msolve_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    298\u001b[39m x = result[\u001b[33m\"\u001b[39m\u001b[33mx\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    299\u001b[39m y = result[\u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/l2o/SS_Learning_MIQP_1/.venv/lib/python3.12/site-packages/diffcp/cone_program.py:351\u001b[39m, in \u001b[36msolve_internal\u001b[39m\u001b[34m(A, b, c, cone_dict, solve_method, warm_start, raise_on_error, **kwargs)\u001b[39m\n\u001b[32m    349\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m status.lower() != \u001b[33m\"\u001b[39m\u001b[33msolved\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    350\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raise_on_error:\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m SolverError(\u001b[33m\"\u001b[39m\u001b[33mSolver scs returned status \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m % status)\n\u001b[32m    352\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    353\u001b[39m         result[\u001b[33m\"\u001b[39m\u001b[33mD\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mSolverError\u001b[39m: Solver scs returned status unbounded"
     ]
    }
   ],
   "source": [
    "for x, y, p, pu in train_loader:\n",
    "    print(x.shape, y.shape, p.shape)\n",
    "    \n",
    "    u_opt, p_opt, v_opt, s_opt = cplayer(\n",
    "        x[:, 0:2], x[:, 2:4], x[:, 4:6], y\n",
    "    )\n",
    "    \n",
    "    # print(u_opt)\n",
    "    # print(pu)\n",
    "    \n",
    "    threshold = 1e-3\n",
    "    diff = torch.abs(u_opt - pu).clone()\n",
    "    diff[diff < threshold] = 0\n",
    "    print(diff.mean(dim=0))\n",
    "    \n",
    "    # print('--------------------------\\n\\n')\n",
    "    # # print(p_opt)\n",
    "    # # print(v_opt)\n",
    "    # # print(v_opt.shape)\n",
    "    # # print(p)\n",
    "    \n",
    "    # # print(torch.abs(torch.cat([p_opt, v_opt], dim=1) - p))\n",
    "    \n",
    "    threshold = 1e-3\n",
    "    diff = torch.abs(torch.cat([p_opt, v_opt], dim=1) - p).clone()\n",
    "    diff[diff < threshold] = 0\n",
    "    print(diff.mean(dim=0))\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c9966d",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a5bc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdbb2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 6\n",
    "n_output = 4\n",
    "\n",
    "nn_model = MLPWithSTE(insize=n_input, outsize=n_output,\n",
    "                bias=True,\n",
    "                linear_map=torch.nn.Linear,\n",
    "                nonlin=nn.ReLU,\n",
    "                hsizes=[128] * 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad77eff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = SSL_MIQP_incorporated(nn_model, cplayer, 6, 4, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e106208",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ground_truth_solver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m training_params[\u001b[33m'\u001b[39m\u001b[33mWEIGHT_DECAY\u001b[39m\u001b[33m'\u001b[39m] = \u001b[32m1e-5\u001b[39m\n\u001b[32m      9\u001b[39m training_params[\u001b[33m'\u001b[39m\u001b[33mPATIENCE\u001b[39m\u001b[33m'\u001b[39m] = \u001b[32m5\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m Model.train_SL(\u001b[43mground_truth_solver\u001b[49m, train_loader, test_loader, training_params)\n",
      "\u001b[31mNameError\u001b[39m: name 'ground_truth_solver' is not defined"
     ]
    }
   ],
   "source": [
    "from gurobipy import gurobi\n",
    "\n",
    "\n",
    "training_params = {}\n",
    "training_params['TRAINING_EPOCHS'] = int(1)\n",
    "training_params['CHECKPOINT_AFTER'] = int(20)\n",
    "training_params['LEARNING_RATE'] = 1e-3\n",
    "training_params['WEIGHT_DECAY'] = 1e-5\n",
    "training_params['PATIENCE'] = 5\n",
    "\n",
    "Model.train_SL(ground_truth_solver, train_loader, test_loader, training_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SS_Learning_MIQP_1 (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
