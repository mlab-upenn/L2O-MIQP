{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17fa082b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "\n",
    "from src.neural_net import *\n",
    "from cvxpy_dpc_layer import *\n",
    "from trainer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a8bd587",
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle = np.load(\"data/data.npz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f58b7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bundle[\"X\"]; Y = bundle[\"Y\"]; U = bundle[\"U\"]; Xtraj = bundle[\"Xtraj\"]\n",
    "OBJ = bundle[\"OBJ\"]; status = bundle[\"STATUS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fc6d53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test, U_train, U_test, Xtraj_train, Xtraj_test, OBJ_train, OBJ_test = train_test_split(\n",
    "    X, Y, U, Xtraj, OBJ, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19e6d6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "Y_train_tensor = torch.tensor(Y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "Y_test_tensor = torch.tensor(Y_test, dtype=torch.float32)\n",
    "U_train_tensor = torch.tensor(U_train, dtype=torch.float32)\n",
    "U_test_tensor = torch.tensor(U_test, dtype=torch.float32)\n",
    "Xtraj_train_tensor = torch.tensor(Xtraj_train, dtype=torch.float32)\n",
    "Xtraj_test_tensor = torch.tensor(Xtraj_test, dtype=torch.float32)\n",
    "# OBJ_train_tensor = torch.tensor(OBJ_train, dtype=torch.float32)\n",
    "# OBJ_test_tensor = torch.tensor(OBJ_test, dtype=torch.float32)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(\n",
    "    X_train_tensor, Y_train_tensor, Xtraj_train_tensor, U_train_tensor\n",
    ")\n",
    "test_dataset = torch.utils.data.TensorDataset(\n",
    "    X_test_tensor, Y_test_tensor, Xtraj_test_tensor, U_test_tensor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4c5ccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ebb7bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_lab/workspace/l2o/SS_Learning_MIQP_1/.venv/lib/python3.12/site-packages/cvxpy/expressions/expression.py:498: FutureWarning: \n",
      "    You didn't specify the order of the flatten expression. The default order\n",
      "    used in CVXPY is Fortran ('F') order. This default will change to match NumPy's\n",
      "    default order ('C') in a future version of CVXPY.\n",
      "    To suppress this warning, please specify the order explicitly.\n",
      "    \n",
      "  warnings.warn(flatten_order_warning, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "cp_layer = build_dpc_cvxpy_layer(N=20, use_soft=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e16ac07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _obj_function(u_opt, x_opt, y, meta=None):\n",
    "#     \"\"\"\n",
    "#     Example objective function computation.\n",
    "#     Args:\n",
    "#         u_opt: Optimal control inputs (B, H, 2)\n",
    "#         x_opt: Optimal states (B, H+1, 2)\n",
    "#         y: integer variables (B, H) - delta values in {0,1,2,3}\n",
    "#         meta: Dictionary containing objective parameters\n",
    "#     Returns:\n",
    "#         Objective value tensor (B,).\n",
    "#     \"\"\"\n",
    "#     device = u_opt.device\n",
    "#     B, H, _ = u_opt.shape\n",
    "    \n",
    "#     # Default weights (from data_collection.py)\n",
    "#     if meta is None:\n",
    "#         Q = torch.eye(2, device=device)           # state cost\n",
    "#         R = torch.eye(2, device=device) * 0.5           # control cost\n",
    "#         P = torch.eye(2, device=device)           # terminal cost\n",
    "#         rho = torch.tensor(0.1, device=device)    # integer variable penalty\n",
    "#         x_ref = torch.tensor([4.2, 1.8], device=device).view(1, 1, 2).expand(B, H+1, 2)\n",
    "#     else:\n",
    "#         Q = meta.get('Q', torch.eye(2)).to(device)\n",
    "#         R = meta.get('R', torch.eye(2)).to(device)\n",
    "#         P = meta.get('P', torch.eye(2)).to(device)\n",
    "#         rho = meta.get('rho', torch.tensor(0.1)).to(device)\n",
    "#         x_ref = meta.get('x_ref', torch.tensor([4.2, 1.8], device=device).view(1, 1, 2).expand(B, H+1, 2)).to(device)\n",
    "    \n",
    "#     # Stage costs over horizon (k = 0 to H-1)\n",
    "#     # State cost: sum_k (x_k - x_ref)^T Q (x_k - x_ref)\n",
    "#     state_error = x_opt[:, :-1, :] - x_ref[:, :-1, :]  # (B, H, 2) - exclude terminal state\n",
    "#     state_cost = torch.einsum('bhi,ij,bhj->b', state_error, Q, state_error)\n",
    "    \n",
    "#     # Control cost: sum_k u_k^T R u_k\n",
    "#     control_cost = torch.einsum('bhi,ij,bhj->b', u_opt, R, u_opt)\n",
    "    \n",
    "#     # Integer variable penalty: sum_k rho * delta_k^2\n",
    "#     if y.dim() == 2:  # (B, H)\n",
    "#         integer_penalty = rho * (y ** 2).sum(dim=1)  # (B,)\n",
    "#     elif y.dim() == 3:  # (B, H, 1) or similar\n",
    "#         integer_penalty = rho * (y ** 2).sum(dim=[1, 2])  # (B,)\n",
    "#     else:\n",
    "#         integer_penalty = torch.zeros(B, device=device)\n",
    "\n",
    "#     # Terminal cost: (x_N - x_ref)^T P (x_N - x_ref)\n",
    "#     terminal_error = x_opt[:, -1, :] - x_ref[:, -1, :]  # (B, 2)\n",
    "#     terminal_cost = torch.einsum('bi,ij,bj->b', terminal_error, P, terminal_error)\n",
    "    \n",
    "#     # Total objective\n",
    "#     obj = state_cost + control_cost + integer_penalty + terminal_cost  # (B,)\n",
    "#     return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7e57f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x, y, u, x_traj, obj in train_loader:\n",
    "#     print(x.shape, y.shape)\n",
    "#     x0 = x[:, 0:2]\n",
    "#     d = x[:, 2:].reshape(-1, 20, 2)\n",
    "\n",
    "#     print(y.shape)\n",
    "\n",
    "#     x_opt, u_opt, s_opt = cp_layer(x0, d, y)\n",
    "\n",
    "#     # print(x.shape)\n",
    "#     print(x_opt.shape, u_opt.shape)\n",
    "#     print(x_traj.shape, u.shape)\n",
    "\n",
    "#     threshold = 1e-3\n",
    "#     diff_x = x_opt - x_traj\n",
    "#     diff_u = u_opt - u\n",
    "    \n",
    "#     print(\"X trajectory differences (ignoring < threshold):\")\n",
    "#     print(diff_x[torch.abs(diff_x) >= threshold])\n",
    "    \n",
    "#     print(\"\\nControl input differences (ignoring < threshold):\")\n",
    "#     print(diff_u[torch.abs(diff_u) >= threshold])\n",
    "\n",
    "#     # print(torch.mean(_obj_function(u_opt, x_opt, y) - obj))\n",
    "#     print(torch.mean(_obj_function(u, x_traj, y) - obj))\n",
    "#     print(torch.mean(_obj_function(u, x_traj, y) - torch.mean(_obj_function(u_opt, x_opt, y))))\n",
    "#     # print()\n",
    "\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97bfb86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model_0 = MLPWithSoftmaxSTE(\n",
    "    insize=42,\n",
    "    outsize=20,\n",
    "    integer_choices=[0, 1, 2, 3],\n",
    "    hsizes=[128] * 4\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69f749dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "dt_string = now.strftime(\"%Y%m%d_%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2f38fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmux2001\u001b[0m (\u001b[33mmux2001-xxxxxlab-test1\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/x_lab/workspace/l2o/SS_Learning_MIQP_1/mi-dpc/wandb/run-20251105_163742-w5jza2i4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mux2001-xxxxxlab-test1/l2o_ssl_miqp_dpc/runs/w5jza2i4' target=\"_blank\">sl_20251105_163741</a></strong> to <a href='https://wandb.ai/mux2001-xxxxxlab-test1/l2o_ssl_miqp_dpc' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mux2001-xxxxxlab-test1/l2o_ssl_miqp_dpc' target=\"_blank\">https://wandb.ai/mux2001-xxxxxlab-test1/l2o_ssl_miqp_dpc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mux2001-xxxxxlab-test1/l2o_ssl_miqp_dpc/runs/w5jza2i4' target=\"_blank\">https://wandb.ai/mux2001-xxxxxlab-test1/l2o_ssl_miqp_dpc/runs/w5jza2i4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1 | step 1] training loss = 0.9078, validation loss = 0.9269\n",
      "[epoch 1 | step 50] training loss = 0.3990, validation loss = 0.3622\n",
      "[epoch 2 | step 100] training loss = 0.2662, validation loss = 0.2458\n",
      "[epoch 3 | step 150] training loss = 0.2170, validation loss = 0.2057\n",
      "[epoch 4 | step 200] training loss = 0.1627, validation loss = 0.1802\n",
      "[epoch 4 | step 250] training loss = 0.1807, validation loss = 0.1649\n",
      "[epoch 5 | step 300] training loss = 0.1643, validation loss = 0.1559\n",
      "[epoch 6 | step 350] training loss = 0.1570, validation loss = 0.1532\n",
      "[epoch 7 | step 400] training loss = 0.1346, validation loss = 0.1444\n",
      "[epoch 8 | step 450] training loss = 0.1490, validation loss = 0.1420\n",
      "[epoch 8 | step 500] training loss = 0.1314, validation loss = 0.1328\n",
      "[epoch 9 | step 550] training loss = 0.1238, validation loss = 0.1349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 10 | step 600] training loss = 0.1342, validation loss = 0.1296\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▆▆▆▇█</td></tr><tr><td>step</td><td>▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/loss</td><td>█▆▅▅▄▃▂▂▂▂▂▂▂▂▂▁▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁</td></tr><tr><td>val/loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>step</td><td>629</td></tr><tr><td>train/loss</td><td>0.13945</td></tr><tr><td>val/loss</td><td>0.12962</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sl_20251105_163741</strong> at: <a href='https://wandb.ai/mux2001-xxxxxlab-test1/l2o_ssl_miqp_dpc/runs/w5jza2i4' target=\"_blank\">https://wandb.ai/mux2001-xxxxxlab-test1/l2o_ssl_miqp_dpc/runs/w5jza2i4</a><br> View project at: <a href='https://wandb.ai/mux2001-xxxxxlab-test1/l2o_ssl_miqp_dpc' target=\"_blank\">https://wandb.ai/mux2001-xxxxxlab-test1/l2o_ssl_miqp_dpc</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251105_163742-w5jza2i4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_params = {}\n",
    "training_params['TRAINING_EPOCHS'] = int(10)\n",
    "training_params['CHECKPOINT_AFTER'] = int(50)\n",
    "training_params['LEARNING_RATE'] = 1e-3\n",
    "training_params['WEIGHT_DECAY'] = 1e-5\n",
    "training_params['PATIENCE'] = 5\n",
    "training_params['WANDB_PROJECT'] = \"l2o_ssl_miqp_dpc\"\n",
    "training_params['RUN_NAME'] = \"sl_\" + dt_string\n",
    "\n",
    "\n",
    "Trainer_SL = SSL_MIQPP_Trainer(\n",
    "    nn_model=nn_model_0,\n",
    "    cvx_layer=cp_layer,\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    ")\n",
    "\n",
    "Trainer_SL.train_SL(\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    training_params=training_params,\n",
    "    wandb_log=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e58e581d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "avg_obj_val: 636.9917\n",
      "avg_optimality_gap: 334.7316\n",
      "avg_slack_penalty: 0.0494\n",
      "avg_y_penalty: 0.0000\n",
      "avg_supervised_loss: 0.1265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'avg_obj_val': 636.99169921875,\n",
       " 'avg_optimality_gap': 334.73162841796875,\n",
       " 'avg_slack_penalty': 0.049377962946891785,\n",
       " 'avg_y_penalty': 0.0,\n",
       " 'avg_supervised_loss': 0.12654297053813934}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Trainer_SL.evaluate(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c250949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0829a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/x_lab/workspace/l2o/SS_Learning_MIQP_1/mi-dpc/wandb/run-20251105_163746-l99ku9fs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mux2001-xxxxxlab-test1/l2o_ssl_miqp_dpc/runs/l99ku9fs' target=\"_blank\">sl_20251105_163741</a></strong> to <a href='https://wandb.ai/mux2001-xxxxxlab-test1/l2o_ssl_miqp_dpc' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mux2001-xxxxxlab-test1/l2o_ssl_miqp_dpc' target=\"_blank\">https://wandb.ai/mux2001-xxxxxlab-test1/l2o_ssl_miqp_dpc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mux2001-xxxxxlab-test1/l2o_ssl_miqp_dpc/runs/l99ku9fs' target=\"_blank\">https://wandb.ai/mux2001-xxxxxlab-test1/l2o_ssl_miqp_dpc/runs/l99ku9fs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1 | step 1] validation: loss = 0.5985, obj_val = 2720.9929, opt_gap = 2103.8789 %, slack_pen = 0.2574, y_penalty = 0.0000, supervised_loss = 0.9123, \n",
      "[epoch 1 | step 50] validation: loss = 0.1996, obj_val = 617.8381, opt_gap = 400.4204 %, slack_pen = 0.0490, y_penalty = 0.0000, supervised_loss = 0.3441, \n",
      "[epoch 2 | step 100] validation: loss = 0.1420, obj_val = 378.4980, opt_gap = 206.5659 %, slack_pen = 0.0254, y_penalty = 0.0000, supervised_loss = 0.2549, \n",
      "[epoch 3 | step 150] validation: loss = 0.1075, obj_val = 326.8928, opt_gap = 164.7681 %, slack_pen = 0.0204, y_penalty = 0.0000, supervised_loss = 0.1914, \n",
      "[epoch 4 | step 200] validation: loss = 0.1050, obj_val = 314.0634, opt_gap = 154.3768 %, slack_pen = 0.0191, y_penalty = 0.0000, supervised_loss = 0.1877, \n",
      "[epoch 4 | step 250] validation: loss = 0.0888, obj_val = 309.6043, opt_gap = 150.7652 %, slack_pen = 0.0187, y_penalty = 0.0000, supervised_loss = 0.1559, \n",
      "[epoch 5 | step 300] validation: loss = 0.0900, obj_val = 313.8616, opt_gap = 154.2135 %, slack_pen = 0.0192, y_penalty = 0.0000, supervised_loss = 0.1576, \n",
      "[epoch 6 | step 350] validation: loss = 0.0832, obj_val = 306.9389, opt_gap = 148.6064 %, slack_pen = 0.0185, y_penalty = 0.0000, supervised_loss = 0.1449, \n",
      "[epoch 7 | step 400] validation: loss = 0.0820, obj_val = 335.4430, opt_gap = 171.6934 %, slack_pen = 0.0213, y_penalty = 0.0000, supervised_loss = 0.1393, \n",
      "[epoch 8 | step 450] validation: loss = 0.0762, obj_val = 305.1025, opt_gap = 147.1190 %, slack_pen = 0.0183, y_penalty = 0.0000, supervised_loss = 0.1311, \n",
      "[epoch 8 | step 500] validation: loss = 0.0745, obj_val = 299.4409, opt_gap = 142.5333 %, slack_pen = 0.0177, y_penalty = 0.0000, supervised_loss = 0.1283, \n",
      "[epoch 9 | step 550] validation: loss = 0.0771, obj_val = 301.6426, opt_gap = 144.3166 %, slack_pen = 0.0180, y_penalty = 0.0000, supervised_loss = 0.1332, \n",
      "[epoch 10 | step 600] validation: loss = 0.0740, obj_val = 309.0545, opt_gap = 150.3199 %, slack_pen = 0.0187, y_penalty = 0.0000, supervised_loss = 0.1262, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▆▆▆▇█</td></tr><tr><td>step</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█</td></tr><tr><td>train/combined_loss</td><td>█▆▃▃▂▂▂▂▂▂▂▁▂▁▂▁▂▁▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/obj_val</td><td>█▄▃▂▃▂▂▂▂▂▃▂▄▂▂▁▂▃▅▃▁▂▁▂▃▁▁▂▂▇▅▄▂▁▁▃▂▂▂▂</td></tr><tr><td>train/slack_pen</td><td>█▆▃▂▂▂▂▂▁▁▂▁▅▁▁▂▃▂▄▃▃▂▁▁▁▁▂▅▂▂▂▂▁▂▂▂▂▃▂▂</td></tr><tr><td>train/supervised_loss</td><td>█▇▆▃▃▃▃▃▂▂▂▂▁▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/y_penalty</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/avg_loss</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/obj_val</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/slack_pen</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>step</td><td>629</td></tr><tr><td>train/combined_loss</td><td>0.0986</td></tr><tr><td>train/obj_val</td><td>551.21106</td></tr><tr><td>train/slack_pen</td><td>0.0413</td></tr><tr><td>train/supervised_loss</td><td>0.15039</td></tr><tr><td>train/y_penalty</td><td>0</td></tr><tr><td>val/avg_loss</td><td>0.07398</td></tr><tr><td>val/obj_val</td><td>309.05447</td></tr><tr><td>val/slack_pen</td><td>0.01871</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sl_20251105_163741</strong> at: <a href='https://wandb.ai/mux2001-xxxxxlab-test1/l2o_ssl_miqp_dpc/runs/l99ku9fs' target=\"_blank\">https://wandb.ai/mux2001-xxxxxlab-test1/l2o_ssl_miqp_dpc/runs/l99ku9fs</a><br> View project at: <a href='https://wandb.ai/mux2001-xxxxxlab-test1/l2o_ssl_miqp_dpc' target=\"_blank\">https://wandb.ai/mux2001-xxxxxlab-test1/l2o_ssl_miqp_dpc</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251105_163746-l99ku9fs/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn_model = MLPWithSoftmaxSTE(\n",
    "    insize=42,\n",
    "    outsize=20,\n",
    "    integer_choices=[0, 1, 2, 3],\n",
    "    hsizes=[128] * 4\n",
    ")\n",
    "\n",
    "Trainer_SSL = SSL_MIQPP_Trainer(\n",
    "    nn_model=nn_model,\n",
    "    cvx_layer=cp_layer,\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    ")\n",
    "\n",
    "\n",
    "slack_weight = 1e5\n",
    "constraint_weight = 0\n",
    "supervised_weight = 1e5\n",
    "loss_weights = [1.0, slack_weight, constraint_weight, supervised_weight]\n",
    "\n",
    "Trainer_SSL.train_SSL(\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    training_params=training_params,\n",
    "    loss_weights=loss_weights,\n",
    "    wandb_log=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fbd5c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "avg_obj_val: 620.1743\n",
      "avg_optimality_gap: 322.8466\n",
      "avg_slack_penalty: 0.0477\n",
      "avg_y_penalty: 0.0000\n",
      "avg_supervised_loss: 0.1291\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'avg_obj_val': 620.1742553710938,\n",
       " 'avg_optimality_gap': 322.8466491699219,\n",
       " 'avg_slack_penalty': 0.04769348353147507,\n",
       " 'avg_y_penalty': 0.0,\n",
       " 'avg_supervised_loss': 0.12907715141773224}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Trainer_SSL.evaluate(test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SS_Learning_MIQP_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
