{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad71911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "from cvxpylayers.torch import CvxpyLayer\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import multiprocessing as mp\n",
    "import sys\n",
    "import os\n",
    "import wandb\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "from neural_net import *\n",
    "from cvxlayer import CVXLayer\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabcc2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class example_QP(CVXLayer):\n",
    "\n",
    "    def __init__(self, nx, ny, penalty=\"l1\", rho1=1.0, bigM = 1e3, **kwargs):\n",
    "        self.nx = nx\n",
    "        self.ny = ny\n",
    "        # Define CVXPY variables and parameters\n",
    "        x = cp.Variable((nx,))  # continuous decision variables\n",
    "        y = cp.Parameter((ny,))  # integer decision variables\n",
    "\n",
    "        p = cp.Parameter((nx,))  # linear term in the objective\n",
    "        b = cp.Parameter((nx,))  # RHS of the constraint x <= b\n",
    "        a = cp.Parameter((1,))   # RHS of the constraint 1.T*x <= a\n",
    "        s = cp.Variable((nx,), nonneg=True)  # slack variables\n",
    "        \n",
    "        # Define the QP problem\n",
    "        if penalty == \"l1\": # default to l1 penalty\n",
    "            objective = cp.Minimize(cp.quad_form(x, np.eye(nx)) + p.T @ x + rho1*cp.sum(s))\n",
    "        elif penalty == \"l2\": \n",
    "            objective = cp.Minimize(cp.quad_form(x, np.eye(nx)) + p.T @ x + rho1*cp.quad_form(s, np.eye(nx)))\n",
    "        constraints = [\n",
    "            x <= b,\n",
    "            sum(x) <= a,\n",
    "            x <= bigM * y + s,\n",
    "            s >= 0,\n",
    "        ]\n",
    "        problem = cp.Problem(objective, constraints)\n",
    "\n",
    "        # Create CVXPY layer\n",
    "        self.cvxpylayer = CvxpyLayer(problem, parameters=[p, b, a, y], variables=[x, s])        \n",
    "\n",
    "    def solve(self, theta, y):\n",
    "        \"\"\"\n",
    "        Run the CVXPYLayer in batch. All inputs are torch tensors.\n",
    "        Returns x, s (each torch tensor with grad).\n",
    "        \"\"\"\n",
    "        p = theta[:, :self.nx]\n",
    "        b = theta[:, self.nx:2*self.nx]\n",
    "        a = theta[:, -1]\n",
    "\n",
    "        if a.ndim == 1:\n",
    "            a = a.unsqueeze(-1)\n",
    "\n",
    "        # Device management\n",
    "        device = p.device\n",
    "        self.cvxpylayer = self.cvxpylayer.to(device)\n",
    "        p = p.to(device)\n",
    "        b = b.to(device)\n",
    "        a = a.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        x_opt, s_opt = self.cvxpylayer(p, b, a, y)\n",
    "        return x_opt, s_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565d7646",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = 2; ny = 2 \n",
    "\n",
    "def _solve_single_miqp(args):\n",
    "    \"\"\"Helper function to solve a single MIQP problem.\"\"\"\n",
    "    # Redirect stdout and stderr to devnull at the start of each process\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "    sys.stderr = open(os.devnull, 'w')\n",
    "    \"\"\"Helper function to solve a single MIQP problem.\"\"\"\n",
    "    i, p_i, b_i, a_i, nx, ny = args\n",
    "    \n",
    "    # Variables\n",
    "    x = cp.Variable(nx)\n",
    "    y = cp.Variable(ny, boolean=True)\n",
    "    \n",
    "    # Objective and constraints\n",
    "    objective = cp.Minimize(cp.sum_squares(x) + p_i @ x)\n",
    "    constraints = [\n",
    "        x <= b_i,\n",
    "        cp.sum(x) <= a_i,\n",
    "        cp.sum(y) <= 1,\n",
    "        x <= 1e3 * y\n",
    "    ]\n",
    "    \n",
    "    # Problem definition\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    \n",
    "    try:\n",
    "        prob.solve(solver=cp.GUROBI, verbose=False, OutputFlag=0)\n",
    "        \n",
    "        if x.value is not None and y.value is not None:\n",
    "            return i, x.value, y.value\n",
    "        else:\n",
    "            return i, np.zeros(nx), np.zeros(ny)\n",
    "    except Exception as e:\n",
    "        print(f\"Error solving sample {i}: {e}\")\n",
    "        return i, np.zeros(nx), np.zeros(ny)\n",
    "\n",
    "@torch.no_grad()\n",
    "def GUROBI_solve_parallel(p: torch.Tensor, b: torch.Tensor, a: torch.Tensor, max_workers=None):\n",
    "    \"\"\"\n",
    "    Solve MIQP for each sample in the batch using parallel processing.\n",
    "    \"\"\"\n",
    "    device = p.device\n",
    "    p_np = p.detach().cpu().numpy()\n",
    "    b_np = b.detach().cpu().numpy()\n",
    "    a_np = a.detach().cpu().numpy()\n",
    "    \n",
    "    if a_np.ndim == 2:\n",
    "        a_np = a_np.squeeze(-1)\n",
    "    \n",
    "    B = p_np.shape[0]\n",
    "    \n",
    "    # Prepare arguments for parallel execution\n",
    "    args_list = [(i, p_np[i], b_np[i], a_np[i], nx, ny) for i in range(B)]\n",
    "    \n",
    "    # Preallocate result arrays\n",
    "    x_results = np.zeros((B, nx))\n",
    "    y_results = np.zeros((B, ny))\n",
    "    \n",
    "    # Use ProcessPoolExecutor for parallel solving\n",
    "    if max_workers is None:\n",
    "        max_workers = min(B, mp.cpu_count())\n",
    "    \n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(_solve_single_miqp, args): args[0] for args in args_list}\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            i, x_sol, y_sol = future.result()\n",
    "            x_results[i] = x_sol\n",
    "            y_results[i] = y_sol\n",
    "    \n",
    "    return torch.tensor(x_results).float().to(device), torch.tensor(y_results).float().to(device)\n",
    "\n",
    "def ground_truth_solver(theta: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Solve the MIQP problem using Gurobi for ground truth labels.\n",
    "    Args:\n",
    "        theta: Tensor of shape (B, 2n+1) where each row is [p, b, a].\n",
    "    Returns:\n",
    "        x_solver: Tensor of shape (B, n) with optimal continuous variables. \n",
    "    \"\"\"\n",
    "    p = theta[:, :nx]\n",
    "    b = theta[:, nx:2*nx]\n",
    "    a = theta[:, 2*nx].unsqueeze(-1)\n",
    "    x_solver, y_solver = GUROBI_solve_parallel(p, b, a)\n",
    "    return x_solver, y_solver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6402d30d",
   "metadata": {},
   "source": [
    "# Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bad55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem setup\n",
    "nx = 2  # number of continuous decision variables\n",
    "ny = 2  # number of integer decision variables\n",
    "data_seed = 18\n",
    "np.random.seed(data_seed)\n",
    "torch.manual_seed(data_seed)\n",
    "\n",
    "p_low, p_high = -30.0, 5.0   # linear term in objective\n",
    "b_low, b_high = 5.0, 25.0    # RHS of constraint x <= b\n",
    "a_low, a_high = 10.0, 30.0   # RHS of constraint 1^T x <= a\n",
    "\n",
    "ntrain = 50000\n",
    "ntest = 1000\n",
    "\n",
    "# Generate samples\n",
    "samples_train = {\n",
    "    \"p\": torch.FloatTensor(ntrain, nx).uniform_(p_low, p_high),\n",
    "    \"b\": torch.FloatTensor(ntrain, nx).uniform_(b_low, b_high),\n",
    "    \"a\": torch.FloatTensor(ntrain, 1).uniform_(a_low, a_high),\n",
    "}\n",
    "samples_train = torch.concat([samples_train['p'], samples_train['b'], samples_train['a']], dim=-1)\n",
    "\n",
    "samples_test = {\n",
    "    \"p\": torch.FloatTensor(ntest, nx).uniform_(p_low, p_high),\n",
    "    \"b\": torch.FloatTensor(ntest, nx).uniform_(b_low, b_high),\n",
    "    \"a\": torch.FloatTensor(ntest, 1).uniform_(a_low, a_high),\n",
    "}\n",
    "samples_test = torch.concat([samples_test['p'], samples_test['b'], samples_test['a']], dim=-1)\n",
    "\n",
    "# --- Custom dataset class ---\n",
    "class SampleDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, samples):\n",
    "        self.samples = samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = SampleDataset(samples_train)\n",
    "test_dataset = SampleDataset(samples_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b88700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "batch_size = 500\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57c6134",
   "metadata": {},
   "source": [
    "### Create the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7366a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SL_model = MLPWithSTE(insize=2*nx+1, outsize=ny,\n",
    "                bias=True,\n",
    "                linear_map=torch.nn.Linear,\n",
    "                nonlin=nn.ReLU,\n",
    "                hsizes=[128] * 2)\n",
    "\n",
    "\n",
    "\n",
    "slack_weight = 1e3\n",
    "constraint_weight = 1e6\n",
    "supervised_weight = 1e5\n",
    "cvx_layer = example_QP(nx=nx, ny=ny, penalty=\"l1\", rho1=slack_weight)\n",
    "\n",
    "Model = SSL_MIQP_incorporated(SL_model, cvx_layer, nx, ny, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251973ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_params = {}\n",
    "# training_params['TRAINING_EPOCHS'] = int(1)\n",
    "# training_params['CHECKPOINT_AFTER'] = int(20)\n",
    "# training_params['LEARNING_RATE'] = 1e-3\n",
    "# training_params['WEIGHT_DECAY'] = 1e-5\n",
    "# training_params['PATIENCE'] = 5\n",
    "\n",
    "# Model.train_SL(ground_truth_solver, train_loader, test_loader, training_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c19c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    device\n",
    "    nn_model\n",
    "except NameError:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    nn_model = MLPWithSTE(insize=2*nx+1, outsize=ny,\n",
    "                bias=True,\n",
    "                linear_map=torch.nn.Linear,\n",
    "                nonlin=nn.ReLU,\n",
    "                hsizes=[128] * 2)\n",
    "\n",
    "# Then refine with with self-supervised learning\n",
    "training_params = {}\n",
    "training_params['TRAINING_EPOCHS'] = int(10)\n",
    "training_params['CHECKPOINT_AFTER'] = int(20)\n",
    "training_params['LEARNING_RATE'] = 1e-4\n",
    "training_params['WEIGHT_DECAY'] = 1e-5\n",
    "training_params['PATIENCE'] = 10    \n",
    "\n",
    "slack_weight = 1e3\n",
    "constraint_weight = 1e6\n",
    "supervised_weight = 1e5\n",
    "loss_weights = [0.0, slack_weight, constraint_weight, supervised_weight]\n",
    "def quad_fcn(x, y, theta): \n",
    "    p = theta[:, :nx]\n",
    "    return (x**2).sum(dim=1) + (p*x).sum(dim=1)\n",
    "def y_sum_con(y, theta):\n",
    "    return torch.sum(y, dim=-1) - 1.0  # should be <= 0\n",
    "y_cons = [y_sum_con]\n",
    "\n",
    "Model.train_SSL(ground_truth_solver, train_loader, test_loader, training_params, loss_weights, obj_fcn=quad_fcn, y_cons=y_cons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca7548d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b19b225",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "penn_env312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
